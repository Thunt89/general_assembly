{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# NLP Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's exercise we have ~15,000 tweets aimed at various US airlines. Their sentiments are pre-labelled, and it's your task to build a classifier that can predict a tweet's sentiment based on its text.\n",
    "\n",
    "#### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment         airline  \\\n",
       "0           neutral  Virgin America   \n",
       "1          positive  Virgin America   \n",
       "2           neutral  Virgin America   \n",
       "3          negative  Virgin America   \n",
       "4          negative  Virgin America   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../assets/data/airline_tweets.csv\", encoding=\"latin-1\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: Exploration\n",
    "\n",
    "- how many airlines are there?\n",
    "- what is the proportion of sentiment across tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.626913\n",
       "neutral     0.211680\n",
       "positive    0.161407\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of imbalance in both airlines and sentiment, but we'll see how it performs!\n",
    "\n",
    "The \"baseline\" accuracy is 62%, as we could achieve that by just predicting everything as negative, so that's the score to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment    0\n",
       "airline              0\n",
       "text                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Data cleaning\n",
    "\n",
    "- tidy up the tweets as you see fit\n",
    "- you might want to remove Twitter handles for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'said.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the approach on a single tweet\n",
    "tweet = df[\"text\"].values[0]\n",
    "\n",
    "words_remove_handle = [w.lower() for w in tweet.split() if not w.startswith(\"@\")]\n",
    "words_remove_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One word has a full stop, which we could remove manually, but the CountVectorizer will also take care of it for us.\n",
    "\n",
    "Let's verify this by making `words_remove_handle` above into a single string and passing it through the `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'what': 1, 'said': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec.fit([\" \".join(words_remove_handle)])\n",
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean_up_tweet(tweet):\n",
    "    # step 1: remove handles and stitch back into a single string\n",
    "    words_no_handles = [w.lower() for w in tweet.split() if not w.startswith(\"@\")]\n",
    "    # step 2: stemming\n",
    "    return \" \".join([stemmer.stem(w) for w in words_no_handles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>what said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>plus you'v ad commerci to the experience... ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>i didn't today... must mean i need to take ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>it realli aggress to blast obnoxi \"entertainme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>and it a realli big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment         airline  \\\n",
       "0           neutral  Virgin America   \n",
       "1          positive  Virgin America   \n",
       "2           neutral  Virgin America   \n",
       "3          negative  Virgin America   \n",
       "4          negative  Virgin America   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0                                         what said.  \n",
       "1  plus you'v ad commerci to the experience... ta...  \n",
       "2  i didn't today... must mean i need to take ano...  \n",
       "3  it realli aggress to blast obnoxi \"entertainme...  \n",
       "4             and it a realli big bad thing about it  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_cleaned\"] = df[\"text\"].apply(clean_up_tweet)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Train-test split\n",
    "\n",
    "Do a train-test split so we can test our best algorithm at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text_cleaned\"],\n",
    "                                                    df[\"airline_sentiment\"],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df[\"airline_sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Try a simple binary count-based model\n",
    "\n",
    "- Transform your raw text into binary features\n",
    "- *Hint: it's a simple parameter change in `CountVectorizer`*\n",
    "- Choose an appropriate machine learning model for the task\n",
    "- Use cross-validation to evaluate your model's performance on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7285323932926829\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_vectorizer(vec, X, y):\n",
    "    X_train_text = vec.fit_transform(X)\n",
    "    rf = RandomForestClassifier()\n",
    "    accuracy_scores = cross_val_score(rf, X_train_text, y, scoring=\"accuracy\", cv=5)\n",
    "    print(\"Accuracy: \", np.mean(accuracy_scores))\n",
    "\n",
    "evaluate_vectorizer(CountVectorizer(binary=True, stop_words=\"english\"), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: Try playing around with some of the options in `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.731753525152439\n"
     ]
    }
   ],
   "source": [
    "evaluate_vectorizer(CountVectorizer(binary=False, stop_words=\"english\", min_df=2), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7278498475609755\n"
     ]
    }
   ],
   "source": [
    "evaluate_vectorizer(CountVectorizer(binary=False,\n",
    "                                    stop_words=\"english\",\n",
    "                                    min_df=2,\n",
    "                                    ngram_range=(1, 2),\n",
    "                                    max_features=2000),\n",
    "                    X_train,\n",
    "                    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary model seems to actually work slightly better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6: Try moving to a TF-IDF model. Can you improve on your best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7324354039634147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "evaluate_vectorizer(TfidfVectorizer(stop_words=\"english\",\n",
    "                                    min_df=2),\n",
    "                    X_train,\n",
    "                    y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7326318597560976\n"
     ]
    }
   ],
   "source": [
    "evaluate_vectorizer(TfidfVectorizer(stop_words=\"english\",\n",
    "                                    min_df=2,\n",
    "                                    ngram_range=(1, 2)),\n",
    "                    X_train,\n",
    "                    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7: Evaluate your best model (the one with the highest cross-validated score) on your test set. What is its final performance?\n",
    "\n",
    "When you evaluate your model on the test set, remember to **only fit your Vectorizer on the training set** and use the fit Vectorizer to transform the test set. This is just like the rule for using z-score standardisation. We don't want the test set to interfere in our data transformations.\n",
    "\n",
    "Also make sure to look at more than just a single score - consider printing the confusion matrix for example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7447632058287796\n",
      "[[2463  193   97]\n",
      " [ 439  410   81]\n",
      " [ 203  108  398]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "vec = TfidfVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))\n",
    "X_train_text = vec.fit_transform(X_train)\n",
    "X_test_text = vec.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_text, y_train)\n",
    "y_pred = rf.predict(X_test_text)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just so we know what the rows correspond to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2753\n",
       "neutral      930\n",
       "positive     709\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we're better at identifying negative reviews, surprisingly OK at positive ones, and terrible at neutral ones.\n",
    "\n",
    "Perhaps it makes more sense to only look for positive vs. negative - that would probably get a better result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
