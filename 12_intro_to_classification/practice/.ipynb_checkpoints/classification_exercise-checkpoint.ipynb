{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use water pump data from DrivenData.org\n",
    "\n",
    "Your goal is to predict the operating condition of a waterpoint for each record in the dataset.\n",
    "\n",
    "It is a multiclass classification problem with `status_group` as the target class.\n",
    "\n",
    "Take some time to read the data dictionary here: [https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/25](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../assets/data/water_pumps.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: There are a lot of columns, so instead of performing the usual EDA on *all* columns, choose 3-4 columns to focus on and explore the data checking for (among other things):\n",
    "\n",
    "- missing values\n",
    "- strange values\n",
    "- distributions and relationships in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columbs do we intuitivley think could be a good source of prediction\n",
    "select_cols =  [\"construction_year\", \"extraction_type\", \"water_quality\", \"population\",\"status_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see size of dataframe:\n",
    "# df.shape = 59400 rows, 41 columns\n",
    "# Check to see what would happen if you dropped any row with a column that had a null value\n",
    "# df.dropna(inplace=True) --> df.shape = 28k rows (i.e. has probably deleted too much data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "construction_year    0\n",
       "extraction_type      0\n",
       "water_quality        0\n",
       "population           0\n",
       "status_group         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if the selected columns have any null values that need to be dropped - none of them do\n",
    "df[select_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>population</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gravity</td>\n",
       "      <td>soft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26780</td>\n",
       "      <td>50818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1300.652475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.909983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>951.620547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471.482176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1986.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        construction_year extraction_type water_quality    population  \\\n",
       "count        59400.000000           59400         59400  59400.000000   \n",
       "unique                NaN              18             8           NaN   \n",
       "top                   NaN         gravity          soft           NaN   \n",
       "freq                  NaN           26780         50818           NaN   \n",
       "mean          1300.652475             NaN           NaN    179.909983   \n",
       "std            951.620547             NaN           NaN    471.482176   \n",
       "min              0.000000             NaN           NaN      0.000000   \n",
       "25%              0.000000             NaN           NaN      0.000000   \n",
       "50%           1986.000000             NaN           NaN     25.000000   \n",
       "75%           2004.000000             NaN           NaN    215.000000   \n",
       "max           2013.000000             NaN           NaN  30500.000000   \n",
       "\n",
       "       status_group  \n",
       "count         59400  \n",
       "unique            3  \n",
       "top      functional  \n",
       "freq          32259  \n",
       "mean            NaN  \n",
       "std             NaN  \n",
       "min             NaN  \n",
       "25%             NaN  \n",
       "50%             NaN  \n",
       "75%             NaN  \n",
       "max             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at min / max etc. to understand strange values\n",
    "df[select_cols].describe(include='all')\n",
    "# Identifies that there are missing values in both the construction_year and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the data where the construction year data is present, likewise with population\n",
    "df = df.loc[df[\"construction_year\"] > 0, :]\n",
    "df = df.loc[df[\"population\"] > 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: how many rows are there in each class/label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>functional</th>\n",
       "      <td>20709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional needs repair</th>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non functional</th>\n",
       "      <td>14136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "status_group                  \n",
       "functional               20709\n",
       "functional needs repair   2499\n",
       "non functional           14136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A class or label is whether the pump is: 'functional', 'functional needs repair' or 'non functional'\n",
    "df.groupby('status_group')['id'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, as the data currently stands there are categorical features which KNN model cannot deal with. \n",
    "# As with regression, these categorical features need to be translated into dummy features first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extraction_type\n",
       "cemo                             1\n",
       "other - mkulima/shinyanga        1\n",
       "walimi                           2\n",
       "climax                           8\n",
       "other - play pump               50\n",
       "windmill                        61\n",
       "india mark iii                  63\n",
       "other - swn 81                 175\n",
       "other - rope pump              384\n",
       "afridev                        969\n",
       "ksb                           1036\n",
       "mono                          1545\n",
       "india mark ii                 1556\n",
       "swn 80                        2129\n",
       "nira/tanira                   2742\n",
       "other                         3670\n",
       "submersible                   3935\n",
       "gravity                      19017\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, we need a suitable sample size for each category of a feature. So first have a look to see where this is not true\n",
    "df.groupby('extraction_type')['id'].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then 'clean' up the data to remove excessive sample errors by reducing the number of categories\n",
    "df[\"extraction_type\"].replace({'cemo': 'other',\n",
    "                               'other - mkulima/shinyanga' : 'other',\n",
    "                               'walimi': 'other',\n",
    "                               'climax': 'other',\n",
    "                               'other - play pump': 'other',\n",
    "                               'windmill' : 'other',\n",
    "                               'india mark iii' : 'india mark',\n",
    "                               'india mark ii' : 'india mark',\n",
    "                               'other - swn 81': 'swn 80/81',\n",
    "                               'swn 80': 'swn 80/81',\n",
    "                               'other - rope pump':'other'\n",
    "                              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water_quality\n",
       "fluoride abandoned        9\n",
       "milky                   136\n",
       "salty abandoned         166\n",
       "fluoride                167\n",
       "coloured                224\n",
       "unknown                1153\n",
       "salty                  3300\n",
       "soft                  32189\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('water_quality')['id'].count().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"water_quality\"].replace({'fluoride abandoned': 'fluoride',\n",
    "                             'salty abandoned': 'salty',\n",
    "                              }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['construction_year', 'population', 'status_group',\n",
      "       'extraction_type_gravity', 'extraction_type_india mark',\n",
      "       'extraction_type_ksb', 'extraction_type_mono',\n",
      "       'extraction_type_nira/tanira', 'extraction_type_other',\n",
      "       'extraction_type_submersible', 'extraction_type_swn 80/81',\n",
      "       'water_quality_fluoride', 'water_quality_milky', 'water_quality_salty',\n",
      "       'water_quality_soft', 'water_quality_unknown'],\n",
      "      dtype='object')\n",
      "(37344, 16)\n"
     ]
    }
   ],
   "source": [
    "# Get dummy variables for the categorical features\n",
    "df_with_dummies = pd.get_dummies(df.loc[:,select_cols], columns=['extraction_type', 'water_quality'], drop_first=True)\n",
    "print (df_with_dummies.columns)\n",
    "print (df_with_dummies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: Do a train-test split. What is the make-up of the labels in your train and test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26140 11204\n",
      "26140 11204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = df_with_dummies\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"status_group\", axis=1),\n",
    "                                                    df[\"status_group\"],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Using your training set, obtain a basic KNN model's cross-validated accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6461085326669047"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carry out a KNN model fit and prediction, not using any kFolds\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5: Look at the confusion matrix: where are the mistakes?\n",
    "\n",
    "`cross_val_score` doesn't give us a predictor, so you may have to train one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means that cross_val only gives you an error score of your model. \n",
    "# It doesn't actually tell you what the model is to run predictions from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5066,   82, 1022],\n",
       "       [ 521,   52,  202],\n",
       "       [2089,   49, 2121]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate confusion matrix of predictions (rows), vs. outcomes (columns)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_matrix / conf_matrix.sum(axis=1)\n",
    "import numpy as np\n",
    "cm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the confusion matrix \n",
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = cm\n",
    "s = conf_matrix.shape[0]\n",
    "#r = index=[\"stage 1\", \"stage 2\", \"stage 3\"]\n",
    "r = df.groupby('status_group').agg(['count']).index\n",
    "\n",
    "df_cm = pd.DataFrame(array, index=r, columns=r)\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "sbs.set(font_scale=1.4)#for label size\n",
    "sbs.heatmap(df_cm, cmap=\"YlGnBu\", annot=True,annot_kws={\"size\": 16});# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\t0.6447972456006121\n",
      "Fold 2\t0.6400153022188217\n",
      "Fold 3\t0.6373374139250191\n",
      "Fold 4\t0.6390589135424637\n",
      "Fold 5\t0.635424636572303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['functional', 'functional', 'non functional', ..., 'functional',\n",
       "       'non functional', 'non functional'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UPDATE MODEL TO INCLUDE A NUMBER OF K-FOLDS (i.e. cross validation)\n",
    "# NOTE THIS IS THE MANUAL METHOD THAT ALLOWS YOU TO TRAIN A PREDICTOR (fancy term for get out a model)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = df.drop(\"status_group\", axis=1)\n",
    "y = df[\"status_group\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "K_fold_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set the fold count\n",
    "i = 1\n",
    "# Set the vehicle to store the models spun up from each fold\n",
    "models ={}\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in K_fold_cv.split(X_train, y_train):\n",
    "    print(f\"Fold {i}\", end=\"\\t\")\n",
    "    i += 1\n",
    "    \n",
    "    X_train_local = X_train.iloc[train_index]\n",
    "    y_train_local = y_train.iloc[train_index]\n",
    "    \n",
    "    # Reset the model each time, using KNeighborsClassifer as we are working with categorical data\n",
    "    model = KNeighborsClassifier(n_neighbors=7)\n",
    "    # Fit the model to the training fold\n",
    "    model.fit(X_train_local, y_train_local)\n",
    "    models[i] = model\n",
    "    \n",
    "    # Create a prediction for y based on the training fold test_index - this is the local test data, not the global\n",
    "    y_pred = model.predict(X_train.iloc[test_index])\n",
    "    acc = accuracy_score(y_train.iloc[test_index], y_pred)\n",
    "    print (acc)\n",
    "    scores.append(acc)\n",
    "     \n",
    "# Use Fold 5 (the best one) to predict the outcomes of the global test data\n",
    "f_pred = models[5].predict(X_test)\n",
    "f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639326702371844"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean accuracy score for model above with k=5 and KNeighborsClassifier(n_neighbors=7)\n",
    "s = 0\n",
    "for i in scores:\n",
    "    s += i\n",
    "s/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64658635 0.62860968 0.63236419 0.63733741 0.64638347]\n",
      "0.6382562192391881\n"
     ]
    }
   ],
   "source": [
    "# The quick way to do accuracy tests is with cv_scores, but then you can't extract the model (and the predictive power, as above)\n",
    "# This checks the model is stable, and test n_neighbors, or right alpha for regularisation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6: BONUS - obtain a better value for k using grid search - how much can you improve your score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6317901203617864\n",
      "0.6391354289846635\n",
      "0.6425021486336653\n",
      "0.6382562192391881\n",
      "0.6398238814913644\n",
      "0.6400154447463126\n",
      "0.6401688978503542\n",
      "0.6407814422334953\n"
     ]
    }
   ],
   "source": [
    "# This is meant to iterate through k nearest neighbors, not number of folds\n",
    "grid = np.array(range(2, 10))\n",
    "scores = []\n",
    "\n",
    "def gridsearch(k, X_train_loc, y_train_loc):\n",
    "    model = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    cv_scores = cross_val_score(model, X_train_loc, y_train_loc, cv=k)\n",
    "    scores.append(cv_scores.mean())\n",
    "    print(cv_scores.mean())\n",
    "    \n",
    "for k in grid:\n",
    "    gridsearch(k, X_train, y_train)\n",
    "    \n",
    "# I.e. maximum score occurs when k = 5 and cv_score = 0.6414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7: BONUS: what else can you do to improve your score?\n",
    "\n",
    "Try:\n",
    "\n",
    "- standardisation: to make KNN consider features equally\n",
    "- stratification: to improve on the \"representativeness\" of your samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.554552\n",
       "non functional             0.378539\n",
       "functional needs repair    0.066909\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "functional                 0.554534\n",
       "non functional             0.378526\n",
       "functional needs repair    0.066940\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stratification\n",
    "df2 = df_with_dummies\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(df2.drop(\"status_group\", axis=1),\n",
    "                                                            df2[\"status_group\"],\n",
    "                                                            test_size=0.3,\n",
    "                                                            random_state=1,\n",
    "                                                            stratify=y)\n",
    "\n",
    "display(y_train_2.value_counts() / len(y_train_2))\n",
    "display(y_test_2.value_counts() / len(y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6252108335799456\n",
      "0.6343918557330852\n",
      "0.6337413706680765\n",
      "0.6389824411042293\n",
      "0.639518031030199\n",
      "0.6407798031879953\n",
      "0.6405128007334098\n",
      "0.6417747562750956\n"
     ]
    }
   ],
   "source": [
    "# Recheck what the best value of kFolds is for cross-validation, once stratify has been applied to the training data\n",
    "scores = []\n",
    "for k in grid:\n",
    "    gridsearch(k, X_train_2, y_train_2)\n",
    "\n",
    "# I.e. maximum score occurs when k = 9 and cv_score = 0.6418 (basically the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING FEATURES TO BE BETWEEN 0 and 1\n",
    "df3 = df_with_dummies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X3 = df3.drop(\"status_group\", axis=1)\n",
    "y3 = df3[\"status_group\"]\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X3,\n",
    "                                                    y3,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y3)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# NOTE - you should only transform continuous columns - so this is not good practice\n",
    "\n",
    "X_train_transformed = scaler.fit_transform(X_train_3)\n",
    "# do NOT fit the scaler on the test set! Use the already fit scaler from above!\n",
    "X_test_transformed = scaler.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6552411367150874\n",
      "0.663312869388801\n",
      "0.6656083471116144\n",
      "0.6650343006845443\n",
      "0.6647664996339727\n",
      "0.6676355741824823\n",
      "0.6660672028678418\n",
      "0.6684773995891913\n"
     ]
    }
   ],
   "source": [
    "# Recheck what the best value of kFolds is for cross-validation, once stratify\n",
    "# AND scaling of features has been applied to the training data \n",
    "scores = []\n",
    "for k in grid:\n",
    "    gridsearch(k, X_train_transformed, y_train_3)\n",
    "\n",
    "# I.e. maximum score occurs when k = 9 and cv_score = 0.668 (a couple of percent better than without scaling!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.667707961442342"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train_transformed, y_train_3)\n",
    "y_pred = knn.predict(X_test_transformed)\n",
    "accuracy_score(y_test_3, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things I should have done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6395179801071156 {'n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "# Should have done gridsearch to optimise for n_neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    param_grid={\"n_neighbors\": [3, 5, 7, 9]},\n",
    "                    scoring=\"accuracy\",\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_score_, grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
